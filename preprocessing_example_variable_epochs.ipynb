{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypeline\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import mne_bids\n",
    "from contextlib import contextmanager\n",
    "import mne\n",
    "from datetime import datetime\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject to analyze:  ['18']\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"../raw_data\"  # directory where your raw data (folder containing brainvision, eyetracking asc, and behavior is stored)\n",
    "data_dir = \"../data\"  # where to output data\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "file_prefix = \"\"  # prefix to your vhdr files. Assuming it is in the format [prefix]_[number]\n",
    "\n",
    "overwrite_subs = False  # if you want to overwrite the data for a subject, set to True\n",
    "# TO PREPROCESS: 04 (session split across 2 recordings, which aren't concatenating well)\n",
    "subject_dirs = [\"18\"]  # if you want to analyze a specific subset of subjects\n",
    "\n",
    "if len(subject_dirs) == 0:\n",
    "    subject_dirs = sorted(glob(\"*\", root_dir=parent_dir))\n",
    "if not overwrite_subs:\n",
    "    subject_dirs = [sub for sub in subject_dirs if sub not in [f[4:] for f in glob(\"sub-*\", root_dir=data_dir)]]\n",
    "\n",
    "print(\"Subject to analyze: \", subject_dirs)\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"cassia\"  # name of the experiment\n",
    "\n",
    "\n",
    "TRIAL_START_TIME = -0.35  # epoch start before your designated timelock code\n",
    "TRIAL_END_TIME = 2.7\n",
    "BASELINE_TIME = (-0.3, 0)  # time for baseline correction\n",
    "# NOTE: the WM trials are only 1200ms long, but tracking trials are 1,650ms before the delay, 215ms total\n",
    "\n",
    "SRATE = 500  # hz, will resample if different from the raw data srate\n",
    "FILTER_FREQS = (None, 60)  # None to not do one of the filtering steps\n",
    "\n",
    "LINEAR_R2 = 0.3\n",
    "\n",
    "event_dict = {  # this should be a dict of names of ALL the event codes that appear\n",
    "    \"trl_start\": 1,\n",
    "    \"tracking/ss1\": 21,\n",
    "    \"tracking/ss2\": 22,\n",
    "    \"end_of_wm_first_pres\": 2,\n",
    "    \"wm_second_pres\": 3,\n",
    "    \"delay_start\": 4,\n",
    "    \"delay_end\": 5,\n",
    "    \"response\": 6,\n",
    "    \"recording_start\": 9,\n",
    "    \"data_end\": 111,\n",
    "}\n",
    "for setsize in [1, 2]:\n",
    "    for size in [\"small\", \"large\"]:\n",
    "        for bin1 in range(6):\n",
    "            for bin2 in range(6):\n",
    "                final_code_piece = 0\n",
    "                if setsize == 2:\n",
    "                    final_code_piece = bin2 + 1  # we are shifting to 1 index so that 0 = absence\n",
    "                elif setsize == 1 and size == \"large\":\n",
    "                    final_code_piece = bin2 + 1  # that way we know what bins the large cloud spanned\n",
    "                event_dict[f\"WM/ss{setsize}/{bin1}/{final_code_piece}\"] = (\n",
    "                    (setsize - 1) * 100 + (bin1) * 10 + final_code_piece + 30\n",
    "                )  # unique code for the trial, 30 shift keeps it separate from the rest\n",
    "\n",
    "\n",
    "# event_dict is a list of name: number pairings for all the TRIAL event codes\n",
    "# event_code_dict: a dict of code: sequence pairings for each trial\n",
    "# so, if you have a trial with fixation (1) -> SS2 stimulus (12) -> delay (3) -> test (4), that you want to map to code  12:\n",
    "# {12 : [1,12,3,4]}... and so on\n",
    "\n",
    "\n",
    "track_conds = [21, 22]\n",
    "event_code_dict = {\n",
    "    21: [1, 21, 4, 5, 6],\n",
    "    22: [1, 22, 4, 5, 6],\n",
    "}\n",
    "WM_conds = [v for k, v in event_dict.items() if \"WM\" in k]\n",
    "for wmc in WM_conds:\n",
    "    event_code_dict[wmc] = [1, wmc, 4, 5, 6]\n",
    "stim_conditions = track_conds + WM_conds\n",
    "\n",
    "POSITION_TO_TIMELOCK = 1  # which position (IN THE LIST ABOVE) to timelock to. Should be the one which indicates the condition. TODO: make this dynamic\n",
    "\n",
    "EYEKEYWORD = \"SYNC\"\n",
    "\n",
    "# edge case when we forgot to start the recording, manually drop certain trials\n",
    "# Must be in the form of {'subject number':[list of ints]}\n",
    "EEG_TRIALS_DROP = {\n",
    "    \"02\": [352, 353, 354, 355, 356, 1446],  # trials when the eye tracker strangely dropped out\n",
    "    \"12\": [805],\n",
    "    \"18\": [992, 993, 994, 995],\n",
    "}\n",
    "EYE_TRIALS_DROP = {\n",
    "    \"16\": [\n",
    "        1559,\n",
    "        1560,\n",
    "        1561,\n",
    "        1562,\n",
    "        1563,\n",
    "        1564,\n",
    "    ],  # Trials after the EEG recording crashed, but the eye tracker kept running\n",
    "    \"18\": list(np.arange(992, 1006)),\n",
    "}\n",
    "# channels to ignore when rejecting trials. Will also be excluded from analysis.\n",
    "SUB_IGNORE_CHANS = {\n",
    "    \"07\": [\"Fp1\", \"Fp2\"],\n",
    "    \"94\": [\"Fp1\", \"Fp2\"],\n",
    "}\n",
    "\n",
    "NO_EYES = []  # subjects with no eye data\n",
    "DROP_CHANNELS = (\n",
    "    []\n",
    ")  # channels to delete from the dataset entirely. Recommendation is to leave this blank and instead set REJ_TRIALS_IGNORE later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pypeline.Preprocess(\n",
    "    data_dir=data_dir,\n",
    "    root_dir=parent_dir,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    srate=SRATE,\n",
    "    trial_start=TRIAL_START_TIME,\n",
    "    trial_end=TRIAL_END_TIME,\n",
    "    event_dict=event_dict,\n",
    "    event_code_dict=event_code_dict,\n",
    "    timelock_ix=POSITION_TO_TIMELOCK,\n",
    "    baseline_time=BASELINE_TIME,\n",
    "    rejection_time=None,\n",
    "    reject_between_codes=[1, 5],\n",
    "    no_et_spaces=False,\n",
    "    drop_channels=DROP_CHANNELS,\n",
    "    filter_freqs=FILTER_FREQS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "##########################\n",
      "STARTING PREPROCESSING RUN\n",
      "##########################\n",
      "\n",
      "\n",
      "\n",
      "Run started at 10:15:09\n",
      "\n",
      "\n",
      "#############################\n",
      "## STARTING NEW SUBJECT 18 ##\n",
      "#############################\n",
      "\n",
      "More than 1 vhdr file present in subject directory. They will be concatenated in alphabetical order\n",
      "Extracting parameters from ../raw_data/18/18.vhdr...\n",
      "Setting channel info structure...\n",
      "More than 1 vhdr file present in subject directory. They will be concatenated in alphabetical order\n",
      "Extracting parameters from ../raw_data/18/19.vhdr...\n",
      "Setting channel info structure...\n",
      "More than 1 vhdr file present in subject directory. They will be concatenated in alphabetical order\n",
      "Extracting parameters from ../raw_data/18/918.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different highpass filters. Lowest (weakest) filter setting (0.00 Hz) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (500.00 Hz, Nyquist limit) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Not setting positions of 3 eog/misc channels found in montage:\n",
      "['HEOG', 'VEOG', 'StimTrak']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different highpass filters. Lowest (weakest) filter setting (0.00 Hz) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (500.00 Hz, Nyquist limit) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Not setting positions of 3 eog/misc channels found in montage:\n",
      "['HEOG', 'VEOG', 'StimTrak']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different highpass filters. Lowest (weakest) filter setting (0.00 Hz) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (500.00 Hz, Nyquist limit) will be stored.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n",
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:175: RuntimeWarning: Not setting positions of 3 eog/misc channels found in montage:\n",
      "['HEOG', 'VEOG', 'StimTrak']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('New Segment/'), np.str_('Stimulus/S  1'), np.str_('Stimulus/S  4'), np.str_('Stimulus/S  5'), np.str_('Stimulus/S  6'), np.str_('Stimulus/S 21'), np.str_('Stimulus/S 22'), np.str_('Stimulus/S 30'), np.str_('Stimulus/S 32'), np.str_('Stimulus/S 40'), np.str_('Stimulus/S 43'), np.str_('Stimulus/S 50'), np.str_('Stimulus/S 54'), np.str_('Stimulus/S 60'), np.str_('Stimulus/S 65'), np.str_('Stimulus/S 70'), np.str_('Stimulus/S 76'), np.str_('Stimulus/S 80'), np.str_('Stimulus/S 81'), np.str_('Stimulus/S111'), np.str_('Stimulus/S132'), np.str_('Stimulus/S133'), np.str_('Stimulus/S134'), np.str_('Stimulus/S135'), np.str_('Stimulus/S136'), np.str_('Stimulus/S141'), np.str_('Stimulus/S143'), np.str_('Stimulus/S144'), np.str_('Stimulus/S145'), np.str_('Stimulus/S146'), np.str_('Stimulus/S151'), np.str_('Stimulus/S152'), np.str_('Stimulus/S154'), np.str_('Stimulus/S155'), np.str_('Stimulus/S156'), np.str_('Stimulus/S161'), np.str_('Stimulus/S162'), np.str_('Stimulus/S163'), np.str_('Stimulus/S165'), np.str_('Stimulus/S166'), np.str_('Stimulus/S171'), np.str_('Stimulus/S172'), np.str_('Stimulus/S173'), np.str_('Stimulus/S174'), np.str_('Stimulus/S176'), np.str_('Stimulus/S181'), np.str_('Stimulus/S182'), np.str_('Stimulus/S183'), np.str_('Stimulus/S184'), np.str_('Stimulus/S185')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:195: RuntimeWarning: Converting data files to BrainVision format\n",
      "  mne_bids.write_raw_bids(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/preproc_pype/lib/python3.12/site-packages/pybv/io.py:690: UserWarning: Encountered unsupported non-voltage units: n/a\n",
      "Note that the BrainVision format specification supports only ÂµV.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing '../data/sub-18/eeg/sub-18_task-cassia_eeg.json'...\n",
      "Reading 0 ... 9147279  =      0.000 ...  9147.279 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 60 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 60.00 Hz\n",
      "- Upper transition bandwidth: 15.00 Hz (-6 dB cutoff frequency: 67.50 Hz)\n",
      "- Filter length: 221 samples (0.221 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  31 | elapsed:   10.7s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/../data/sub-18/eyetracking/sub-18_task-cassia_eyetracking.asc\n",
      "Pixel coordinate data detected.Pass `scalings=dict(eyegaze=1e3)` when using plot method to make traces more legible.\n",
      "Pupil-size area detected.\n",
      "No fixations were found in this file. Not returning any info on fixations.\n",
      "No saccades were found in this file. Not returning any info on saccades.\n",
      "There are 1709 recording blocks in this file. Times between blocks will be annotated with BAD_ACQ_SKIP.\n",
      "Adding metadata with 84 columns\n",
      "1608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1608 events and 3051 original time points (prior to decimation) ...\n",
      "0 bad epochs dropped\n",
      "Dropped 4 epochs: 992, 993, 994, 995\n",
      "Not setting metadata\n",
      "1618 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1618 events and 3051 original time points (prior to decimation) ...\n",
      "0 bad epochs dropped\n",
      "Dropped 14 epochs: 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:576: RuntimeWarning: The measurement information indicates a low-pass frequency of 500.0 Hz. The decim=2 parameter will result in a sampling frequency of 500.0 Hz, which can cause aliasing artifacts.\n",
      "  eye_epochs = mne.Epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected 35 trials (2.2%) for the following reasons:\n",
      "Peak to peak amplitude: 29 (1.8%)\n",
      "Saccades: 7 (0.4%)\n",
      "Steps: 2 (0.1%)\n",
      "Absolute value: 12 (0.7%)\n",
      "Linear fit: 0 (0.0%)\n",
      "Flatline: 0 (0.0%)\n",
      "\n",
      "Worst electrodes by count:\n",
      "F7: 28\n",
      "FC5: 13\n",
      "ypos_right: 6\n",
      "ypos_left: 6\n",
      "xpos_right: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:1006: RuntimeWarning: This filename (../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_eeg.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs.save(path.fpath, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing participants.tsv ../data/participants.tsv...\n",
      "Summarizing scans.tsv files [PosixPath('../data/sub-13/sub-13_scans.tsv'), PosixPath('../data/sub-14/sub-14_scans.tsv'), PosixPath('../data/sub-15/sub-15_scans.tsv'), PosixPath('../data/sub-12/sub-12_scans.tsv'), PosixPath('../data/sub-08/sub-08_scans.tsv'), PosixPath('../data/sub-01/sub-01_scans.tsv'), PosixPath('../data/sub-06/sub-06_scans.tsv'), PosixPath('../data/sub-07/sub-07_scans.tsv'), PosixPath('../data/sub-09/sub-09_scans.tsv'), PosixPath('../data/sub-17/sub-17_scans.tsv'), PosixPath('../data/sub-10/sub-10_scans.tsv'), PosixPath('../data/sub-18/sub-18_scans.tsv'), PosixPath('../data/sub-11/sub-11_scans.tsv'), PosixPath('../data/sub-16/sub-16_scans.tsv'), PosixPath('../data/sub-05/sub-05_scans.tsv'), PosixPath('../data/sub-02/sub-02_scans.tsv'), PosixPath('../data/sub-94/sub-94_scans.tsv'), PosixPath('../data/sub-03/sub-03_scans.tsv'), PosixPath('../data/sub-04/sub-04_scans.tsv')]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/preprocess.py:1008: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  np.save(path.fpath, epochs.get_data())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The participant template found: sex were all unknown;\n",
      "handedness were all unknown;\n",
      "ages all unknown\n",
      "This dataset was created by [Unspecified] and conforms to BIDS version 1.7.0.\n",
      "This report was generated with MNE-BIDS (https://doi.org/10.21105/joss.01896).\n",
      "The dataset consists of 19 participants (sex were all unknown; handedness were\n",
      "all unknown; ages all unknown) . Data was recorded using an EEG system (Brain\n",
      "Products) sampled at 1000 Hz with line noise at 60 Hz. There were 19 scans in\n",
      "total. Recording durations ranged from 1642.38 to 13126.4 seconds (mean =\n",
      "9732.36, std = 2334.55), for a total of 184914.88 seconds of data recorded over\n",
      "all scans. For each dataset, there were on average 34.0 (std = 0.0) recording\n",
      "channels per scan, out of which 34.0 (std = 0.0) were used in analysis (0.0 +/-\n",
      "0.0 were removed from analysis).\n"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def redirect_stdout(new_stdout):  # writes the output to a log file\n",
    "    save_stdout = sys.stdout\n",
    "    save_stderr = sys.stderr\n",
    "    sys.stdout = new_stdout\n",
    "    sys.stderr = sys.stdout\n",
    "    try:\n",
    "        yield None\n",
    "    finally:\n",
    "        sys.stdout = save_stdout\n",
    "        sys.stderr = save_stderr\n",
    "\n",
    "\n",
    "# with open('preprocessing_log.txt','a+') as f:\n",
    "#     with redirect_stdout(f):\n",
    "\n",
    "print(\"\\n\\n\\n##########################\\n\" + \"STARTING PREPROCESSING RUN\\n\" + \"##########################\\n\\n\\n\")\n",
    "print(f'Run started at {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "for subject_number in subject_dirs:\n",
    "\n",
    "    print(\n",
    "        \"\\n\\n#############################\\n\"\n",
    "        + f\"## STARTING NEW SUBJECT {subject_number} ##\\n\"\n",
    "        + \"#############################\\n\"\n",
    "    )\n",
    "\n",
    "    #####################\n",
    "    #### IMPORT DATA ####\n",
    "    #####################\n",
    "\n",
    "    # import into the RAW bids dataset\n",
    "    eeg, eeg_events = pre.import_eeg(subject_number, overwrite=True)\n",
    "    reref_index = mne.pick_channels(eeg.ch_names, [\"TP9\"])  # TODO: custom rereferencing?\n",
    "    eeg.load_data().apply_function(\n",
    "        pre.rereference_to_average, picks=[\"eeg\"], reref_values=np.squeeze(eeg.get_data()[reref_index])\n",
    "    )\n",
    "    eeg.filter(*pre.filter_freqs, n_jobs=-1)\n",
    "\n",
    "    pre.import_behavior(subject_number)\n",
    "\n",
    "    ########################################\n",
    "    #### PREPROCESS EEG AND MAKE EPOCHS ####\n",
    "    ########################################\n",
    "\n",
    "    if subject_number in NO_EYES:\n",
    "        epochs = pre.make_eeg_epochs(eeg, eeg_events, eeg_trials_drop=EEG_TRIALS_DROP.get(subject_number, None))\n",
    "    else:\n",
    "        eye, eye_events = pre.import_eyetracker(subject_number, keyword=EYEKEYWORD)\n",
    "\n",
    "        epochs = pre.make_and_sync_epochs(\n",
    "            eeg,\n",
    "            eeg_events,\n",
    "            eye,\n",
    "            eye_events,\n",
    "            eeg_trials_drop=EEG_TRIALS_DROP.get(subject_number, None),\n",
    "            eye_trials_drop=EYE_TRIALS_DROP.get(subject_number, None),\n",
    "        )\n",
    "\n",
    "    ###############################\n",
    "    #### DO ARTIFACT REJECTION ####\n",
    "    ###############################\n",
    "\n",
    "    p2p = pre.artreject_slidingP2P(\n",
    "        epochs, rejection_criteria={\"eeg\": 100e-6, \"eog\": 200}, win=200, win_step=100\n",
    "    )  # peak to peak in the window\n",
    "    saccades = pre.artreject_step(\n",
    "        epochs, rejection_criteria={\"eyegaze\": pre.deg2pix(0.5), \"eog\": 50}, win=80, win_step=10\n",
    "    )  # saccades in EOG or eye tracking\n",
    "    steps = pre.artreject_step(\n",
    "        epochs, rejection_criteria={\"eeg\": 60e-6}, win=250, win_step=20\n",
    "    )  # steps (saccade like) in EEG\n",
    "\n",
    "    absolute_value = pre.artreject_value(\n",
    "        epochs, rejection_criteria={\"eyegaze\": pre.deg2pix(1), \"eeg\": 100e-6, \"eog\": 300}\n",
    "    )  # absolute value rejection\n",
    "    linear_fit = pre.artreject_linear(epochs)  # linear fit (drift) rejection\n",
    "    flatline = pre.artreject_flatline(\n",
    "        epochs,\n",
    "        rejection_criteria={\"eeg\": 0, \"eog\": 0, \"eyegaze\": 0},\n",
    "        flatline_duration=200,\n",
    "    )  # check for flatlines\n",
    "\n",
    "    # combine rejection reasons\n",
    "    rej_electrodes = p2p | saccades | steps | absolute_value | linear_fit | flatline\n",
    "    rej_reasons = np.char.array(\n",
    "        np.full(rej_electrodes.shape, \"\", dtype=\"<U30\")\n",
    "    )  # NOTE: dtype is important, must be >= the max possible str length\n",
    "    rej_reasons[p2p] = \"P2P \"\n",
    "    rej_reasons[saccades] = rej_reasons[saccades] + \"SAC \"\n",
    "    rej_reasons[steps] = rej_reasons[steps] + \"STEP \"\n",
    "    rej_reasons[absolute_value] = rej_reasons[absolute_value] + \"ABS \"\n",
    "    rej_reasons[linear_fit] = rej_reasons[linear_fit] + \"LIN \"\n",
    "    rej_reasons[flatline] = rej_reasons[flatline] + \"FLAT \"\n",
    "\n",
    "    rej_counts = lambda x: f\"{x.any(1).sum()} ({round(x.any(1).sum() / x.shape[0] * 100,1)}%)\"\n",
    "    print(\n",
    "        (\n",
    "            f\"Rejected {rej_electrodes.any(1).sum()} trials ({round(rej_electrodes.any(1).sum() / rej_electrodes.shape[0] * 100,1)}%) for the following reasons:\\n\"\n",
    "            f\"Peak to peak amplitude: {rej_counts(p2p)}\\n\"\n",
    "            f\"Saccades: {rej_counts(saccades)}\\n\"\n",
    "            f\"Steps: {rej_counts(steps)}\\n\"\n",
    "            f\"Absolute value: {rej_counts(absolute_value)}\\n\"\n",
    "            f\"Linear fit: {rej_counts(linear_fit)}\\n\"\n",
    "            f\"Flatline: {rej_counts(flatline)}\\n\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Worst electrodes by count:\\n\"\n",
    "        + \"\\n\".join(\n",
    "            [f\"{epochs.ch_names[i]}: {rej_electrodes[:,i].sum()}\" for i in np.argsort(rej_electrodes.sum(0))[::-1][0:5]]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #################################\n",
    "    #### SAVE DATA AS DERIVATIVE ####\n",
    "    #################################\n",
    "\n",
    "    pre.save_all_data(subject_number, epochs, rej_reasons)\n",
    "print(mne_bids.make_report(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_eeg.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -350.00 ...    2700.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/visualizer.py:57: RuntimeWarning: This filename (../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_eeg.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs_obj = mne.read_epochs(self.data_path.fpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 84 columns\n",
      "1604 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "F7 28\n",
      "FC5 13\n",
      "ypos_right 6\n",
      "ypos_left 6\n",
      "xpos_right 3\n",
      "xpos_left 3\n",
      "Fz 2\n",
      "F3 2\n",
      "CP5 2\n",
      "FC1 2\n",
      "C3 2\n",
      "Fp1 2\n",
      "Fp2 2\n",
      "Pz 1\n",
      "PO3 1\n",
      "C4 1\n",
      "Cz 1\n",
      "CP2 1\n",
      "F4 1\n",
      "P7 1\n",
      "P3 1\n",
      "FC2 1\n",
      "CP1 1\n",
      "PO7 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/1604 trials rejected. Saving annotations as \"../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_rejection_flags.npy\"\n",
      "35/1604 trials rejected. Saving annotations as \"../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_rejection_flags.npy\"\n",
      "key not recognized: cmd. Press h for help.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "sub = input('Enter subject number: ') # you can also just set this to a string\n",
    "\n",
    "REJ_CHANNELS_IGNORE=['StimTrak', 'HEOG','VEOG','TP9'] # exclude fp1 and fp2 here if you want to keep trials where they are noisy, and drop them before analysis later\n",
    "\n",
    "\n",
    "viz = pypeline.Visualizer(sub,\n",
    "                            parent_dir = data_dir,\n",
    "                            load_flags = False,  # we're going to rebuild our rejection flags every time\n",
    "                            experiment_name=EXPERIMENT_NAME,\n",
    "                            srate=SRATE,\n",
    "                            rejection_time=[None, None],\n",
    "                            downscale={'eyegaze':1e-6,'misc':1,'eeg':1,'eog':1e-6}, # convert to equivalent units (probably uV)\n",
    "                            channels_drop=['pupil_left','pupil_right'],\n",
    "                            channels_ignore=REJ_CHANNELS_IGNORE + SUB_IGNORE_CHANS.get(sub, []))\n",
    "\n",
    "\n",
    "rejection_sums = viz.rej_chans.sum(axis=0)\n",
    "sort_ix = np.argsort(rejection_sums)[::-1]\n",
    "\n",
    "for ichan,chan in enumerate(viz.chan_labels[sort_ix]):\n",
    "    if rejection_sums[sort_ix][ichan] > 0:\n",
    "        print(chan,rejection_sums[sort_ix][ichan])\n",
    "viz.preprocess_data_for_plot()\n",
    "viz.open_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_eeg.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -350.00 ...    2700.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/cassia/cassia4/preprocessing_pypeline/pypeline/visualizer.py:57: RuntimeWarning: This filename (../data/derivatives/sub-18/eeg/sub-18_task-cassia_desc-preprocessed_eeg.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs_obj = mne.read_epochs(self.data_path.fpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 84 columns\n",
      "1604 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "EVENTS_SHOW: \n",
      "['trl_start', 'tracking/ss1', 'tracking/ss2', 'end_of_wm_first_pres', 'wm_second_pres', 'delay_start', 'delay_end', 'response', 'recording_start', 'data_end', 'WM/ss1/0/0', 'WM/ss1/1/0', 'WM/ss1/2/0', 'WM/ss1/3/0', 'WM/ss1/4/0', 'WM/ss1/5/0', 'WM/ss1/0/1', 'WM/ss1/0/2', 'WM/ss1/0/3', 'WM/ss1/0/4', 'WM/ss1/0/5', 'WM/ss1/0/6', 'WM/ss1/1/1', 'WM/ss1/1/2', 'WM/ss1/1/3', 'WM/ss1/1/4', 'WM/ss1/1/5', 'WM/ss1/1/6', 'WM/ss1/2/1', 'WM/ss1/2/2', 'WM/ss1/2/3', 'WM/ss1/2/4', 'WM/ss1/2/5', 'WM/ss1/2/6', 'WM/ss1/3/1', 'WM/ss1/3/2', 'WM/ss1/3/3', 'WM/ss1/3/4', 'WM/ss1/3/5', 'WM/ss1/3/6', 'WM/ss1/4/1', 'WM/ss1/4/2', 'WM/ss1/4/3', 'WM/ss1/4/4', 'WM/ss1/4/5', 'WM/ss1/4/6', 'WM/ss1/5/1', 'WM/ss1/5/2', 'WM/ss1/5/3', 'WM/ss1/5/4', 'WM/ss1/5/5', 'WM/ss1/5/6', 'WM/ss2/0/1', 'WM/ss2/0/2', 'WM/ss2/0/3', 'WM/ss2/0/4', 'WM/ss2/0/5', 'WM/ss2/0/6', 'WM/ss2/1/1', 'WM/ss2/1/2', 'WM/ss2/1/3', 'WM/ss2/1/4', 'WM/ss2/1/5', 'WM/ss2/1/6', 'WM/ss2/2/1', 'WM/ss2/2/2', 'WM/ss2/2/3', 'WM/ss2/2/4', 'WM/ss2/2/5', 'WM/ss2/2/6', 'WM/ss2/3/1', 'WM/ss2/3/2', 'WM/ss2/3/3', 'WM/ss2/3/4', 'WM/ss2/3/5', 'WM/ss2/3/6', 'WM/ss2/4/1', 'WM/ss2/4/2', 'WM/ss2/4/3', 'WM/ss2/4/4', 'WM/ss2/4/5', 'WM/ss2/4/6', 'WM/ss2/5/1', 'WM/ss2/5/2', 'WM/ss2/5/3', 'WM/ss2/5/4', 'WM/ss2/5/5', 'WM/ss2/5/6', 'New Segment/', 'New Segment/LostSamples: 2']\n"
     ]
    }
   ],
   "source": [
    "viz = pypeline.Visualizer(\n",
    "    sub,\n",
    "    parent_dir=data_dir,\n",
    "    load_flags=False,  # we're going to rebuild our rejection flags every time\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    srate=SRATE,\n",
    "    rejection_time=[None, None],\n",
    "    downscale={\"eyegaze\": 1e-6, \"misc\": 1, \"eeg\": 1, \"eog\": 1e-6},  # convert to equivalent units (probably uV)\n",
    "    channels_drop=[\"pupil_left\", \"pupil_right\"],\n",
    "    channels_ignore=REJ_CHANNELS_IGNORE + SUB_IGNORE_CHANS.get(sub, []),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preproc_pype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
