{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import preprocess_eegdata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '../data/raw_data'\n",
    "file_prefix='SCR_' # prefix to your vhdr files. Assuming it is in the format [prefix]_[number]\n",
    "\n",
    "subject_dirs=[]  # if you want to analyze a specific subset of subjects\n",
    "if len(subject_dirs) == 0:\n",
    "    subject_dirs=sorted(glob('*',root_dir=parent_dir))\n",
    "\n",
    "\n",
    "TRIAL_START_TIME=-0.4\n",
    "TRIAL_END_TIME=1.4\n",
    "BASELINE_TIME=(-.25,0)\n",
    "REJECTION_TIME=[-0.25,1.0]\n",
    "\n",
    "SRATE = 500 # hz, will resample if different from 1k\n",
    "FILTER_FREQS=(None,80) # None to not do lowpass\n",
    "\n",
    "LINEAR_R2 = 0.3\n",
    "\n",
    "\n",
    "og_event_dict={\n",
    "    'trl_start':1,\n",
    "    \"A2N\": 12,\n",
    "    \"A4N\": 14,\n",
    "    \"A6N\": 16,\n",
    "    \"A8N\": 18,\n",
    "    \"A2P\": 22,\n",
    "    \"A4P\": 24,\n",
    "    \"A6P\": 26,\n",
    "    \"A8P\": 28,\n",
    "    \"M2N\": 32,\n",
    "    \"M4N\": 34,\n",
    "    \"M6N\": 36,\n",
    "    \"M8N\": 38,\n",
    "    \"M2P\": 42,\n",
    "    \"M4P\": 44,\n",
    "    \"M6P\": 46,\n",
    "    \"M8P\": 48,\n",
    "    'delay_start':2,\n",
    "    'delay_end':4,\n",
    "}\n",
    "event_dict=og_event_dict.copy()\n",
    "event_code_dict={} # define event codes based on sequence\n",
    "\n",
    "stim_conditions=[]\n",
    "for key,ev in og_event_dict.items():\n",
    "    if ev > 10:\n",
    "        event_dict.update({key+'/TARGET':ev+1}) # add in keys for targets\n",
    "        event_code_dict.update({ev:[1,ev,2,4,4]})\n",
    "        event_code_dict.update({ev+1:[1,ev,2,3,2,4,4]})\n",
    "        stim_conditions.extend([ev,ev+1])\n",
    "\n",
    "\n",
    "\n",
    "POSITION_TO_TIMELOCK = 1 # which position (IN THE LIST ABOVE) to timelock to\n",
    "\n",
    "\n",
    "EEG_TRIALS_DROP = {}   # TODO: make this a dict\n",
    "EYE_TRIALS_DROP = {10:[0,1,2,3]} # edge case when we forgot to start the recording, drop certain trials\n",
    "DROP_CHANNELS=[] #['Fp1','Fp2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch, Baseline, Preprocess, and Identy Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preprocess_eegdata.Preprocess(\n",
    "                                    parent_dir=parent_dir,\n",
    "                                    file_prefix='SCR_',\n",
    "                                    trial_start=TRIAL_START_TIME,\n",
    "                                    trial_end=TRIAL_END_TIME,\n",
    "                                    event_dict=event_dict,\n",
    "                                    stim_conditions=stim_conditions,\n",
    "                                    event_code_dict=event_code_dict,\n",
    "                                    timelock_ix=POSITION_TO_TIMELOCK,\n",
    "                                    baseline_time=BASELINE_TIME,\n",
    "                                    rejection_time=REJECTION_TIME,\n",
    "                                    no_et_spaces=False,\n",
    "                                    drop_channels=DROP_CHANNELS,\n",
    "                                    filter_freqs=FILTER_FREQS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting subject 026\n",
      "Extracting parameters from ../data/raw_data/026/SCR_026.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 8950019  =      0.000 ...  8950.019 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryjones/Documents/research/banyan/preprocessing/preprocess_eegdata.py:81: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  eegdata = mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=True)  # read into mne.raw structure\n",
      "/Users/henryjones/Documents/research/banyan/preprocessing/preprocess_eegdata.py:81: RuntimeWarning: Channels contain different highpass filters. Lowest (weakest) filter setting (0.00 Hz) will be stored.\n",
      "  eegdata = mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=True)  # read into mne.raw structure\n",
      "/Users/henryjones/Documents/research/banyan/preprocessing/preprocess_eegdata.py:81: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (500.00 Hz, Nyquist limit) will be stored.\n",
      "  eegdata = mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=True)  # read into mne.raw structure\n",
      "/Users/henryjones/Documents/research/banyan/preprocessing/preprocess_eegdata.py:81: RuntimeWarning: Not setting positions of 3 eog/misc channels found in montage:\n",
      "['HEOG', 'VEOG', 'StimTrak']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  eegdata = mne.io.read_raw_brainvision(eegfile, eog=[\"HEOG\", \"VEOG\"], misc=[\"StimTrak\"], preload=True)  # read into mne.raw structure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 165 samples (0.165 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  31 | elapsed:   11.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  3', 'Stimulus/S  4', 'Stimulus/S 12', 'Stimulus/S 14', 'Stimulus/S 16', 'Stimulus/S 18', 'Stimulus/S 22', 'Stimulus/S 24', 'Stimulus/S 26', 'Stimulus/S 28', 'Stimulus/S 32', 'Stimulus/S 34', 'Stimulus/S 36', 'Stimulus/S 38', 'Stimulus/S 42', 'Stimulus/S 44', 'Stimulus/S 46', 'Stimulus/S 48']\n",
      "Loading /Users/henryjones/Documents/research/banyan/preprocessing/../data/raw_data/026/et_temp.asc\n",
      "Pixel coordinate data detected.Pass `scalings=dict(eyegaze=1e3)` when using plot method to make traces more legible.\n",
      "Pupil-size area detected.\n",
      "No saccades were found in this file. Not returning any info on saccades.\n",
      "There are 1705 recording blocks in this file. Times between blocks will be annotated with BAD_ACQ_SKIP.\n",
      "Used Annotations descriptions: ['ELCL_PCR_PARAM 5 3.0', 'ELCL_PROC CENTROID (3)', 'SYNC 1', 'SYNC 12', 'SYNC 14', 'SYNC 16', 'SYNC 18', 'SYNC 2', 'SYNC 22', 'SYNC 24', 'SYNC 26', 'SYNC 28', 'SYNC 3', 'SYNC 32', 'SYNC 34', 'SYNC 36', 'SYNC 38', 'SYNC 4', 'SYNC 42', 'SYNC 44', 'SYNC 46', 'SYNC 48']\n",
      "Not setting metadata\n",
      "1598 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1598 events and 1801 original time points (prior to decimation) ...\n",
      "0 bad epochs dropped\n",
      "Dropped 0 epochs: \n",
      "Not setting metadata\n",
      "1598 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1598 events and 1801 original time points (prior to decimation) ...\n",
      "0 bad epochs dropped\n",
      "Dropped 0 epochs: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g5/_50pp0f95mx6v6d1_3b33r700000gn/T/ipykernel_94297/1466436217.py:33: RuntimeWarning: The measurement information indicates a low-pass frequency of 500.0 Hz. The decim=2 parameter will result in a sampling frequency of 500.0 Hz, which can cause aliasing artifacts.\n",
      "  eye_epochs = mne.Epochs(eye,eye_events,pre.event_dict,tmin=pre.trial_start_t,tmax=pre.trial_end_t,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "for sub in subject_dirs:\n",
    "    print(f'Starting subject {sub}')\n",
    "            \n",
    "    subject_dir = os.path.join(pre.parent_dir,sub)\n",
    "\n",
    "    # load in EEG and eye data\n",
    "    eeg,eeg_events,eeg_event_dict = pre.load_eeg(subject_dir)\n",
    "    eye,eye_events,et_event_dict = pre.load_eyetracking(subject_dir)\n",
    "\n",
    "\n",
    "    # delete any events that do not appear in both ET and EEG (usually a boundary)\n",
    "    unmatched_codes = list(set(eeg_event_dict.values()) ^ set(et_event_dict.values())) \n",
    "    eeg_events=eeg_events[~ np.isin(eeg_events,unmatched_codes).any(axis=1)]\n",
    "    eye_events = eye_events[~ np.isin(eye_events,unmatched_codes).any(axis=1)]\n",
    "    eeg_events = pre.filter_events(eeg_events)\n",
    "    eye_events = pre.filter_events(eye_events)\n",
    "\n",
    "    \n",
    "\n",
    "    # build epochs for EEG and eyetracking\n",
    "    assert eeg.info['sfreq'] % SRATE == 0\n",
    "    decim = eeg.info['sfreq'] / SRATE\n",
    "    eeg_epochs = mne.Epochs(eeg,eeg_events,pre.event_dict,tmin=pre.trial_start_t,tmax=pre.trial_end_t,\n",
    "                            on_missing='ignore',baseline=pre.baseline_time,\n",
    "                            reject_tmin=pre.rejection_time[0],reject_tmax=pre.rejection_time[1],preload=True,decim=decim).drop(EEG_TRIALS_DROP.get(sub, [])) # set up epochs object\n",
    "    if pre.drop_channels is not None:\n",
    "        eeg_epochs = eeg_epochs.drop_channels(pre.drop_channels)\n",
    "\n",
    "    # build epochs for eye tracking\n",
    "    # figure out decim, may be different from EEG\n",
    "    assert eye.info['sfreq'] % SRATE == 0\n",
    "    decim = eye.info['sfreq'] / SRATE\n",
    "    eye_epochs = mne.Epochs(eye,eye_events,pre.event_dict,tmin=pre.trial_start_t,tmax=pre.trial_end_t,\n",
    "                            on_missing='ignore',baseline=pre.baseline_time,reject=None,flat=None,reject_by_annotation=False,preload=True,decim=decim).drop(EYE_TRIALS_DROP.get(sub, []))\n",
    "    \n",
    "    # grab pupil size data to save out, if it exists\n",
    "    pupil_chs = [ch for ch in eye_epochs.ch_names if 'pupil' in ch]\n",
    "    if len(pupil_chs) > 0:\n",
    "        pupil_epochs = eye_epochs.copy().pick(pupil_chs)  \n",
    "        np.save(os.path.join(pre.parent_dir,sub,f'{sub}_pupil'),pupil_epochs.get_data(copy=False))\n",
    "    \n",
    "    eye_epochs = eye_epochs.pick(np.setdiff1d(eye_epochs.ch_names,['pupil_left','pupil_right','DIN'])) # exclude non-location based eye channels\n",
    "\n",
    "    # make sure the same epochs are selected, might vary if mne drops an epoch or 2\n",
    "    if (len(eye_epochs.selection)!=len(eeg_epochs.selection)) or (np.any(eeg_epochs.selection != eye_epochs.selection)):\n",
    "        print('WARNING: EEG and ET trials do not match up, subsetting to overlapping trials')\n",
    "        shared_selection = np.intersect1d(eeg_epochs.selection,eye_epochs.selection)\n",
    "\n",
    "        np.save(os.path.join(pre.parent_dir,sub,f'{sub}_preArt_selections.npy'),shared_selection) # for filtering behavior later\n",
    "\n",
    "        eeg_drops = np.setdiff1d(eeg_epochs.selection,shared_selection)\n",
    "        eye_drops = np.setdiff1d(eye_epochs.selection,shared_selection)\n",
    "\n",
    "        eeg_epochs = eeg_epochs.drop(eeg_drops)\n",
    "        eye_epochs = eye_epochs.drop(eye_drops)\n",
    "\n",
    "\n",
    "    # concatenate EEG and eyetracking\n",
    "    epochs=eeg_epochs.copy()\n",
    "    epochs.add_channels([eye_epochs],force_update_info=True)\n",
    "\n",
    "\n",
    "\n",
    "    # DO REJECTION HERE\n",
    "    # IMPORTANT UNITS: eyegaze in pixels (use deg2pix to convert), EEG in volts, EOG in microvolts\n",
    "    #TODO: fix units?\n",
    "    p2p=pre.artreject_slidingP2P(epochs,rejection_criteria={'eeg':100e-6,'eog':200},win=200,win_step=100)               # peak to peak in the window\n",
    "    saccades = pre.artreject_step(epochs,rejection_criteria={'eyegaze':pre.deg2pix(0.5),'eog':50},win=80,win_step=10)   # saccades in EOG\n",
    "    steps = pre.artreject_step(epochs,rejection_criteria={'eeg':60e-6},win=250,win_step=20)                             # steps (saccade like) in EEG\n",
    "\n",
    "    absolute_value=pre.artreject_value(epochs,rejection_criteria={'eyegaze':pre.deg2pix(1), 'eeg':100e-6, 'eog':300})   # absolute value rejection\n",
    "    linear_fit = pre.artreject_linear(epochs)                                                                           # linear fit (drift) rejection\n",
    "    flatline = pre.artreject_flatline(epochs,rejection_criteria={'eeg':0,'eog':0,'eyegaze':0},flatline_duration=200)    # check for flatlines\n",
    "\n",
    "\n",
    "    # combine rejection reasons\n",
    "    rej_electrodes = p2p | saccades | steps | absolute_value | linear_fit | flatline\n",
    "    rej_reasons = np.char.array(np.full(rej_electrodes.shape,'', dtype=\"<U30\"))  # NOTE: dtype is important, must be >= the max possible str length\n",
    "    rej_reasons[p2p] = 'P2P '\n",
    "    rej_reasons[saccades] = rej_reasons[saccades] + 'SAC '\n",
    "    rej_reasons[steps] = rej_reasons[steps] + 'STEP '\n",
    "    rej_reasons[absolute_value] = rej_reasons[absolute_value] + 'ABS '\n",
    "    rej_reasons[linear_fit] = rej_reasons[linear_fit] + 'LIN '\n",
    "    rej_reasons[flatline] = rej_reasons[flatline] + 'FLAT '\n",
    "\n",
    "\n",
    "    # save files\n",
    "    np.save(os.path.join(pre.parent_dir,sub,f'{sub}_rej.npy'),rej_electrodes)                                   # matrix of trials x electrodes by which were rejected\n",
    "    np.save(os.path.join(pre.parent_dir,sub,f'{sub}_rej_reasons.npy'),rej_reasons)                              # trials x electrodes with rejection reasons\n",
    "    epochs.save(os.path.join(pre.parent_dir,sub,f'{sub}_epo.fif'),overwrite=True)                               # save mne epochs object (for later)\n",
    "    np.save(os.path.join(pre.parent_dir,sub,f'{sub}_epo'),epochs.get_data(copy=False))                          # save data as a npy for ease loading\n",
    "    np.save(os.path.join(pre.parent_dir,sub,f'{sub}_conditions'),eeg_events[:,2])                               # condition labels\n",
    "    pd.Series(epochs.ch_names).to_csv(os.path.join(pre.parent_dir,sub,f'{sub}_chan_labels.csv'),header=False)   # channel labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize and Confirm Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/henryjones/Documents/research/banyan/preprocessing/../data/raw_data/011/011_epo.fif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -400.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "xpos_right 655\n",
      "xpos_left 655\n",
      "ypos_right 635\n",
      "ypos_left 635\n",
      "F8 14\n",
      "Cz 2\n",
      "FC2 1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "REJ_CHANNELS_IGNORE=['HEOG','VEOG','Fp1','Fp2'] # exclude fp1 and fp2 here, they are dropped later\n",
    "\n",
    "\n",
    "viz = preprocess_eegdata.Visualizer(sub,\n",
    "                                    parent_dir = parent_dir,\n",
    "                                    srate=SRATE,\n",
    "                                    timelock=0.2,\n",
    "                                    trial_start = TRIAL_START_TIME,\n",
    "                                    trial_end = TRIAL_END_TIME,\n",
    "                                    rejection_time=REJECTION_TIME,\n",
    "                                    condition_dict = {v:k for k,v in event_dict.items()},\n",
    "                                    downscale={'eyegaze':1e-6,'misc':1e-4,'eeg':1,'eog':1e-6},\n",
    "                                    channels_drop=['StimTrak'],\n",
    "                                    channels_ignore=REJ_CHANNELS_IGNORE)\n",
    "\n",
    "\n",
    "rejection_sums = viz.rej_chans.sum(axis=0)\n",
    "sort_ix = np.argsort(rejection_sums)[::-1]\n",
    "\n",
    "for ichan,chan in enumerate(viz.chan_labels[sort_ix]):\n",
    "    if rejection_sums[sort_ix][ichan] > 0:\n",
    "        print(chan,rejection_sums[sort_ix][ichan])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/1600 trials rejected. Saving annotations as \".../011_rej_FINAL.npy\"\n",
      "674/1600 trials rejected. Saving annotations as \".../011_rej_FINAL.npy\"\n"
     ]
    }
   ],
   "source": [
    "viz.preprocess_data_for_plot()\n",
    "viz.open_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key not recognized: s\n",
      "saving current rejections as rej_FINAL.npy\n"
     ]
    }
   ],
   "source": [
    "# viz.save_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvLoad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
